{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "affa35c2-2a05-4451-8bfb-42f2b56c7d74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports loaded\n✅ MLflow configured\n✅ Data loaded: 8000 rows\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/28 13:16:04 WARNING mlflow.utils.requirements_utils: Found pyspark version (4.0.0+databricks.connect.17.2.2) contains a local version label (+databricks.connect.17.2.2). MLflow logged a pip requirement for this package as 'pyspark==4.0.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n2026/01/28 13:16:08 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /local_disk0/user_tmp_data/spark-79305b81-c676-479d-ae3e-10/tmpccpdkauo/model, flavor: spark). Fall back to return ['pyspark==4.0.0']. Set logging level to DEBUG to see the full traceback. \n\u001B[31m2026/01/28 13:16:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model trained and logged\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Gender</th><th>High_Risk_Percentage</th></tr></thead><tbody><tr><td>Female</td><td>34.56</td></tr><tr><td>Male</td><td>33.56</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Female",
         34.56
        ],
        [
         "Male",
         33.56
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "High_Risk_Percentage",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.824625\nAUC: 0.867984455489115\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>High_Mental_Health_Risk</th><th>prediction</th><th>count</th></tr></thead><tbody><tr><td>0</td><td>0.0</td><td>4306</td></tr><tr><td>1</td><td>0.0</td><td>969</td></tr><tr><td>1</td><td>1.0</td><td>2291</td></tr><tr><td>0</td><td>1.0</td><td>434</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         0.0,
         4306
        ],
        [
         1,
         0.0,
         969
        ],
        [
         1,
         1.0,
         2291
        ],
        [
         0,
         1.0,
         434
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "High_Mental_Health_Risk",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"ml_attr\": {\"num_vals\": 2, \"type\": \"nominal\"}}",
         "name": "prediction",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83C\uDFAF Predictions saved to GOLD\n"
     ]
    }
   ],
   "source": [
    "# MENTAL HEALTH RISK MODEL TRAINING\n",
    "\n",
    "from pyspark.sql.functions import col, when, count, round\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "print(\"✅ Imports loaded\")\n",
    "\n",
    "# ---------------- MLflow Setup ----------------\n",
    "os.environ[\"MLFLOW_DFS_TMP\"] = \"/Volumes/ecommerce/mental_health/mlflow_volume/mlflow_tmp\"\n",
    "mlflow.set_experiment(\"/Shared/Mental_Health_Risk_Prediction\")\n",
    "\n",
    "print(\"✅ MLflow configured\")\n",
    "\n",
    "# ---------------- Load Data ----------------\n",
    "df = spark.table(\"ecommerce.mental_health.gold_ml_features\")\n",
    "print(\"✅ Data loaded:\", df.count(), \"rows\")\n",
    "\n",
    "# ---------------- Feature Vector ----------------\n",
    "feature_cols = [\n",
    "    \"High_Screen_Time\",\n",
    "    \"Sleep_Deprived\",\n",
    "    \"LateNight_Sleep_Risk\",\n",
    "    \"Passive_Usage_Risk\",\n",
    "    \"Social_Comparison_Risk\"\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "# ---------------- Model ----------------\n",
    "rf = RandomForestClassifier(\n",
    "    labelCol=\"High_Mental_Health_Risk\",\n",
    "    featuresCol=\"features\",\n",
    "    numTrees=50,\n",
    "    maxDepth=5\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "# ---------------- Train + Log ----------------\n",
    "with mlflow.start_run(run_name=\"Mental_Health_Risk_Model\"):\n",
    "\n",
    "    model = pipeline.fit(df)\n",
    "    predictions = model.transform(df)\n",
    "\n",
    "    mlflow.spark.log_model(model, \"mental_health_model\")\n",
    "\n",
    "    print(\"✅ Model trained and logged\")\n",
    "\n",
    "# ---------------- AI Insight Table ----------------\n",
    "gender_risk = predictions.groupBy(\"Gender\") \\\n",
    "    .agg(\n",
    "        round(\n",
    "            (count(when(col(\"prediction\") == 1, True)) / count(\"*\")) * 100,\n",
    "            2\n",
    "        ).alias(\"High_Risk_Percentage\")\n",
    "    )\n",
    "\n",
    "display(gender_risk)\n",
    "\n",
    "#-----------------Log Metrics ----------------------\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "# Accuracy\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"High_Mental_Health_Risk\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "\n",
    "# AUC\n",
    "auc_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"High_Mental_Health_Risk\",\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "auc = auc_evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"AUC: {auc}\")\n",
    "\n",
    "\n",
    "#----------------- Confusion metrics ---------------\n",
    "confusion_matrix = predictions.groupBy(\n",
    "    \"High_Mental_Health_Risk\", \"prediction\"\n",
    ").count()\n",
    "\n",
    "display(confusion_matrix)\n",
    "\n",
    "\n",
    "# ---------------- Save Predictions ----------------\n",
    "pred_df_fixed = predictions.select(\n",
    "    \"Age\",\n",
    "    \"Gender\",\n",
    "    \"prediction\",\n",
    "    \"probability\",\n",
    "    \"High_Mental_Health_Risk\"\n",
    ")\n",
    "\n",
    "pred_df_fixed.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"ecommerce.mental_health.gold_user_risk_predictions_fixed\")\n",
    "\n",
    "print(\"\uD83C\uDFAF Predictions saved to GOLD\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5650435595452511,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "05_ML_Model_Training_Mental_Health_Risk",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}